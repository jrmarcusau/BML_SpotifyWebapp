<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Welcome</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="Header" >
        <div class="MusicMusicListFilled" style="width: 40px; height: 40px; position: relative; flex-direction: column; justify-content: flex-start; align-items: flex-start; display: flex">
            
            <img src="music-dropdown.png" alt="dropdown" style="width: 29.17px; height: 25.83px; background: #33333300"></img>
        </div>
        
        <div class="About" style="width: 96px; height: 44px; padding-top: 8px; padding-bottom: 7px; padding-left: 13px; padding-right: 14px; justify-content: center; align-items: center; display: inline-flex">
            <div class="About" style="text-align: center; color: #333333; font-size: 24px; font-family: Inter; font-weight: 400; word-wrap: break-word">About</div>
        </div>
    </div>
    <div class="Main">
        
        <h1> What does this tool do?   </h1>    
        <p>

            This tool utilizes Spotify’s API to find song recommendations for a given, user-inputted “seed” song. From the “seed” song, the tool extracts all of the Spotify MIR features available <link to features explanation page>. Then, the user selects how they would like their output songs to be matched, and the tool identifies N songs that align with the user-inputted criteria. The output of this tool is a .csv file that contains the seed song, recommendations, and Spotify MIR features of all songs. The intention of this tool is to allow for greater experimental control for researchers, or to help music listeners find new music that they may enjoy. 
        </p>
        <h1>
            Why was this tool created?
        </h1>    
        <p>

            This tool was originally created for a project investigating music-evoked emotion; specifically, nostalgia. We aimed to use personalized nostalgic stimuli for each participant, but needed to identify a method of finding musically-matched “control” songs to go along with each personalized nostalgic song. The goal of musically matching songs was to disentangle the effects of the music-evoked emotion from the effects of lower-level musical features such as tempo, or loudness. We used this tool to identify a set of 10 candidate non-nostalgic songs that we then presented to participants to identify whether they were familiar, or nostalgic. Familiar, non-nostalgic songs were selected as eventual Control songs for the study. 

            While the creation of this tool was for one particular case, we envision that this tool will be useful for many different cases and research questions involving music, psychology, neuroscience, and computer science. 
        </p>
        <h1>How do I use this tool?</h1>
            
        <p>
            Collect your seed song(s). In original uses of this tool, we collected seed songs from participants, asking them to list songs that made them feel nostalgic. 
            Decide whether you want to import songs manually or via a spreadsheet.
            If manually, type the title and artist of the song into the text box
            If via spreadsheet, download the template spreadsheet and format your list of songs accordingly. Then upload. 
            Once your songs load, select the musical features that you would like to match based on. For example, perhaps you want to find other songs that were released in the same year as your seed song. Or, maybe you want to find songs that have similar levels of “danceability”. You may select as many criteria as you like. In the original use of this tool, we found that <link to paper, once published> matching based on valence, arousal, release date, and popularity was sufficient to implicitly match for all other features. 
            Click next, and download your output .csv file. This file will contain your seed songs and their features, and your recommendations and their features.
            If you have any questions or suggestions for this tool and how we may improve the website’s general functionality, please contact us <link to form>
            If you encounter a technical bug, please report it <link to bug>. 
            If you use this tool in your research please cite it <link to cite> and let us know <link to contact> so that we can include your work in our database <link to Publications section>

        </p>
            
        <h1>Publications using this tool:</h1>
        <p>
            Blah 
            blah
            blah
        </p>
        <p>
            If you use this tool in your research, please let us know <link to contact form> so that we can add your publication to our database. 
        </p>    
            
        <h1>Tool authors:</h1>
            
        <p>
            This tool was created at the University of Southern California’s Brain and Creativity Institute <link> (directed by Drs. Antonio <link> and Hanna Damasio <Link>), the Brain and Music Lab <link> (directed by Dr. Assal Habibi <link>) and the Signal Analysis and Interpretation Laboratory <link> (directed by Shrikanth Narayanan <link>). 

                [photo] Sarah Hennessy, MA <link> developed this tool while obtaining her PhD in Brain and Cognitive Sciences at USC’s Brain and Creativity Institute and Brain and Music Lab. Her projects in collaboration with Timothy Greer on the neural and behavioral correlates of music-evoked nostalgia utilized this tool to optimize experimental control in nostalgic stimuli. Sarah is now a postdoctoral fellow at [when i figure it out].
    
                [photo] Timothy Greer, PhD,  built this tool while obtaining his PhD in Computer Science at the Signal Analysis and Interpretation Laboratory in USC’s Viterbi School of Engineering. Tim is now an Applied Scientist on Amazon’s Music Personalization Team.
    
                Marcus Au implemented this tool in the public web-based platform from which you view it today while obtaining his Bachelors degree in Computer Science from the University of Southern California. 
    
                Caitlin Noel designed the front end of this website while obtaining her Bachelor’s degree in Neuroscience form the University of Southern California. 
    
        </p>
            
    </div>

    <div class="Footer" >
        <div class="CreatedBySarahHennessyFromTheUscBrainAndMusicLab2023LosAngelesCaLastUpdatedMmDdYyyy" style="text-align: center; color: #333333; font-size: 16px; font-family: Inter; font-weight: 400; word-wrap: break-word">Created by Sarah Hennessy from the USC Brain and Music Lab. This is a personal project on Spotify's public APIs and does not represent Spotify.<br/>2023 ・ Los Angeles, CA ・ Last updated: MM/DD/YYYY</div>
        <div class="CiteThisTool" style="width: 99px; height: 19px; justify-content: center; align-items: center; display: inline-flex">
          <div class="CiteThisTool" style="text-align: center; color: #2B71B2; font-size: 16px; font-family: Inter; font-weight: 400; text-decoration: underline; word-wrap: break-word">Cite this Tool</div>
        </div>
        <div class="BaseBug" style="width: 100%; height: 100%; position: relative">
            <img src="bug.png" alt="bug" style="width: 21.50px; height: 21.50px; left: 1.25px; top: 1.25px; position: absolute; background: #65698600"></img>
        </div>
    </div>

</body>


</html>